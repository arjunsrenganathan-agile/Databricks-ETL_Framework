{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ad074f6-5d18-4688-a479-b5b9985fe201",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_silver_table_config(table_name):\n",
    "    config_df = spark.sql(f\"\"\"\n",
    "        SELECT source_system, silver_table_name, load_type, file_location\n",
    "        FROM silver_control_table\n",
    "        WHERE silver_table_name = '{table_name}'\n",
    "    \"\"\")\n",
    "    return config_df.collect()[0] if not config_df.isEmpty() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5319fbaa-0ddd-400e-8f62-d781ff77a256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_to_table(table_name, layer, log_message, error_flag=False):\n",
    "    timestamp = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "    spark.sql(f\"\"\"\n",
    "        INSERT INTO logging_table (table_name, layer, log_message, log_timestamp, error_flag)\n",
    "        VALUES ('{table_name}', '{layer}', '{log_message}', '{timestamp}', {error_flag})\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee09f530-948c-499a-9cb9-746b0145f580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_data(file_location):\n",
    "    return spark.read.format(\"delta\").load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7527e2fc-765b-4f55-a366-2def115d9555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_to_silver_table(df, silver_table_name):\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(silver_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "402dabd0-e93d-4e4f-9c9e-4ab9b043e267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get silver table names from the tracking table\n",
    "def get_silver_table_names():\n",
    "    silver_tables_df = spark.sql(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM tracking_table \n",
    "        WHERE layer = 'Silver'\n",
    "    \"\"\")\n",
    "    return [row.table_name for row in silver_tables_df.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6f6f984-05f4-4575-a60d-74ac732ade77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def update_tracking_table(table_name, layer):\n",
    "    timestamp = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO tracking_table AS t\n",
    "        USING (SELECT '{table_name}' AS table_name, '{layer}' AS layer, '{timestamp}' AS last_loaded) AS s\n",
    "        ON t.table_name = s.table_name AND t.layer = s.layer\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET last_loaded = s.last_loaded\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT (table_name, layer, last_loaded) VALUES (s.table_name, s.layer, s.last_loaded)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0c65e0c-30cd-4fd4-8245-3cfbe1daac21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the transformation function\n",
    "dbutils.notebook.run(\"/Workspace/Metadata_Driven_ETL_Framework/Transformation_Logic/Transform_Silver_Layer\", 600)\n",
    "\n",
    "def execute_silver_tasks(table_names):\n",
    "    for table_name in table_names:\n",
    "        config = get_silver_table_config(table_name)\n",
    "        if config:\n",
    "            source_system = config.source_system\n",
    "            silver_table_name = config.silver_table_name\n",
    "            load_type = config.load_type\n",
    "            file_location = config.file_location\n",
    "            \n",
    "            try:\n",
    "                # Extract data\n",
    "                df = extract_data(file_location)\n",
    "                log_to_table(silver_table_name, \"Silver\", f\"Successfully extracted data from {file_location}\")\n",
    "\n",
    "                # Transform data\n",
    "                transformed_df = transform_data(df)\n",
    "                log_to_table(silver_table_name, \"Silver\", \"Successfully transformed data\")\n",
    "\n",
    "                # Load data into silver table\n",
    "                load_to_silver_table(transformed_df, silver_table_name)\n",
    "                log_to_table(silver_table_name, \"Silver\", \"Successfully loaded data into silver table\")\n",
    "\n",
    "                # Update tracking table\n",
    "                update_tracking_table(silver_table_name, \"Silver\")\n",
    "                log_to_table(silver_table_name, \"Silver\", \"Successfully updated tracking table\")\n",
    "\n",
    "            except Exception as e:\n",
    "                log_to_table(silver_table_name, \"Silver\", f\"Error processing {table_name}: {e}\", error_flag=True)\n",
    "                print(f\"Error processing {table_name}: {e}\")\n",
    "\n",
    "        else:\n",
    "            log_to_table(table_name, \"Silver\", f\"No configuration found for table: {table_name}\", error_flag=True)\n",
    "            print(f\"No configuration found for table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aecd4e2-5171-4099-9c0e-c705f36e9007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "     # Get the list of silver table names\n",
    "    silver_table_names = get_silver_table_names()\n",
    "        \n",
    "    # Execute the silver tasks\n",
    "    execute_silver_tasks(silver_table_names)\n",
    "\n",
    "except Exception as e:\n",
    "    log_to_table(\"Silver Execution\", \"Silver\", f\"Error during silver table operations: {str(e)}\", error_flag=True)\n",
    "    print(f\"Error during silver table operations: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Build_Silver_Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
