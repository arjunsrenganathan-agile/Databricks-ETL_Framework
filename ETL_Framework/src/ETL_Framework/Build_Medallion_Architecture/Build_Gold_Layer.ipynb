{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e21bcd72-c7c9-4c75-9200-60def7fe720e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_gold_table_config(table_name):\n",
    "    config_df = spark.sql(f\"\"\"\n",
    "        SELECT source_system, gold_table_name, load_type, file_location, silver_schema_name, \n",
    "               dimension_type, fact_type, record_ts, record_is_active\n",
    "        FROM gold_control_table\n",
    "        WHERE gold_table_name = '{table_name}' AND record_is_active = true\n",
    "    \"\"\")\n",
    "    return config_df.collect()[0] if not config_df.isEmpty() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2fc5dec-68e0-4137-b8d1-97d6b4850d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_gold_data(file_location):\n",
    "    return spark.read.format(\"delta\").load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd858343-4f16-4fe0-b122-3690395ea62f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_gold_data(df, config):\n",
    "    if config.load_type == 'DIM':\n",
    "        if config.dimension_type == 'SCD1':\n",
    "            return handle_scd_type_1(df, config.gold_table_name)  # Implement SCD Type 1 handling\n",
    "        elif config.dimension_type == 'SCD2':\n",
    "            return handle_scd_type_2(df, config.gold_table_name)  # Implement SCD Type 2 handling\n",
    "    elif config.load_type == 'FCT':\n",
    "        if config.fact_type == 'transaction':\n",
    "            return handle_transaction_fact(df, config)\n",
    "        elif config.fact_type == 'accumulating':\n",
    "            return handle_accumulating_snapshot(df, config)\n",
    "        elif config.fact_type == 'periodic':\n",
    "            return handle_periodic_snapshot(df, config)\n",
    "        elif config.fact_type == 'insert_only':\n",
    "            return handle_insert_only_fact(df, config)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46895e36-e851-4a22-82c9-5bb5fbbda4bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_to_gold_table(df, gold_table_name):\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(gold_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31508e3d-a163-49fb-b1e5-008e30caf5a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get gold table names from the tracking table\n",
    "def get_gold_table_names():\n",
    "    gold_tables_df = spark.sql(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM tracking_table \n",
    "        WHERE layer = 'Silver'\n",
    "    \"\"\")\n",
    "    return [row.table_name for row in gold_tables_df.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1335e2b5-be1c-40b9-ab4d-8fd68b239aa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_to_table(table_name, layer, log_message, error_flag=False):\n",
    "    timestamp = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "    spark.sql(f\"\"\"\n",
    "        INSERT INTO logging_table (table_name, layer, log_message, log_timestamp, error_flag)\n",
    "        VALUES ('{table_name}', '{layer}', '{log_message}', '{timestamp}', {error_flag})\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15eb835b-954a-4af3-adc7-ee2f617c8602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transform_gold_layer import handle_scd_type_2\n",
    "def transform_gold_data(df, config):\n",
    "    if config.load_type == 'DIM':\n",
    "        # Handle SCD Type 2 for dimension tables\n",
    "        handle_scd_type_2(df, config.gold_table_name)\n",
    "        return spark.table(config.gold_table_name)  # Return updated dimension table\n",
    "    elif config.load_type == 'FCT':\n",
    "        # Transform for fact tables, e.g., aggregating data\n",
    "        return df.groupBy(\"some_column\").agg({\"value_column\": \"sum\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c41fb0f4-0fe6-4b1a-bd1e-612362aa4241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def update_gold_tracking_table(gold_table_name):\n",
    "    timestamp = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO tracking_table AS t\n",
    "        USING (SELECT '{gold_table_name}' AS table_name, 'Gold' AS layer, '{timestamp}' AS last_loaded) AS s\n",
    "        ON t.table_name = s.table_name AND t.layer = s.layer\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET last_loaded = s.last_loaded\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT (table_name, layer, last_loaded) VALUES (s.table_name, s.layer, s.last_loaded)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b404950-52c7-4853-90cb-ecc46ab9346d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def execute_gold_tasks(table_names):\n",
    "    for table_name in table_names:\n",
    "        config = get_gold_table_config(table_name)\n",
    "        if config:\n",
    "            source_system = config.source_system\n",
    "            gold_table_name = config.gold_table_name\n",
    "            load_type = config.load_type\n",
    "            file_location = config.file_location\n",
    "            \n",
    "            try:\n",
    "                # Extract data\n",
    "                df = extract_gold_data(file_location)\n",
    "                log_to_table(gold_table_name, \"Gold\", f\"Successfully extracted data from {file_location}\")\n",
    "\n",
    "                # Transform data\n",
    "                transformed_df = transform_gold_data(df, config)  # This handles SCD Type 2 as needed\n",
    "                log_to_table(gold_table_name, \"Gold\", \"Successfully transformed data\")\n",
    "\n",
    "                # Load data into gold table\n",
    "                load_to_gold_table(transformed_df, gold_table_name)\n",
    "                log_to_table(gold_table_name, \"Gold\", \"Successfully loaded data into gold table\")\n",
    "\n",
    "                # Update tracking table\n",
    "                update_gold_tracking_table(gold_table_name)\n",
    "                log_to_table(gold_table_name, \"Gold\", \"Successfully updated tracking table\")\n",
    "\n",
    "            except Exception as e:\n",
    "                log_to_table(gold_table_name, \"Gold\", f\"Error processing {table_name}: {e}\", error_flag=True)\n",
    "                print(f\"Error processing {table_name}: {e}\")\n",
    "\n",
    "        else:\n",
    "            log_to_table(table_name, \"Gold\", f\"No configuration found for table: {table_name}\", error_flag=True)\n",
    "            print(f\"No configuration found for table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171d1722-49c1-4055-9b00-795610edcc75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the list of gold table names\n",
    "    gold_table_names = get_gold_table_names()\n",
    "    \n",
    "    # Execute the gold tasks\n",
    "    execute_gold_tasks(gold_table_names)\n",
    "\n",
    "except Exception as e:\n",
    "    log_to_table(\"Gold Execution\", \"Gold\", f\"Error during gold table operations: {str(e)}\", error_flag=True)\n",
    "    print(f\"Error during gold table operations: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Build_Gold_Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
