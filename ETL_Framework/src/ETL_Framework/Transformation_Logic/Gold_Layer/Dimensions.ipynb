{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c6dfbb4-4500-4e64-b4ef-d94dd294f70a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def handle_scd_type_1(df, gold_table_name):\n",
    "    # Assume df contains the current data to be updated\n",
    "    # Read the existing records from the gold table\n",
    "    existing_df = spark.table(gold_table_name)\n",
    "\n",
    "    # Perform the update operation (join on the primary key)\n",
    "    updated_df = existing_df.alias(\"existing\").join(\n",
    "        df.alias(\"new\"),\n",
    "        on=\"primary_key\",  # Replace with your actual primary key column\n",
    "        how=\"outer\"\n",
    "    ).select(\n",
    "        \"new.primary_key\",  # Keep the primary key\n",
    "        \"new.column1\",      # New values\n",
    "        \"new.column2\",      # New values\n",
    "        # Add other columns as needed\n",
    "    )\n",
    "\n",
    "    # Write back to the gold table\n",
    "    updated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(gold_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d095506-2ded-4436-9257-209d010850f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def handle_scd_type_2(df, gold_table_name):\n",
    "    # Create a temporary view for the incoming data\n",
    "    df.createOrReplaceTempView(\"incoming_data\")\n",
    "\n",
    "    # MERGE statement to handle SCD Type 2\n",
    "    merge_sql = f\"\"\"\n",
    "    MERGE INTO {gold_table_name} AS existing\n",
    "    USING incoming_data AS incoming\n",
    "    ON existing.business_key = incoming.business_key\n",
    "    WHEN MATCHED AND existing.valid_to IS NULL AND incoming.new_column != existing.existing_column THEN\n",
    "        UPDATE SET \n",
    "            existing.valid_to = current_timestamp(),\n",
    "            existing.is_current = 0  -- Mark old record as inactive\n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT (business_key, new_column, valid_from, valid_to, is_current)\n",
    "        VALUES (incoming.business_key, incoming.new_column, current_timestamp(), NULL, 1)  -- Insert new record\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the MERGE statement\n",
    "    spark.sql(merge_sql)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Dimensions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
